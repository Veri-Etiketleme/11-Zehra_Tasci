{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0a6f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as sia\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from textstat.textstat import *\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23923034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Chakri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Chakri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "614462f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"HateSpeechData.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd6136d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  tweet length  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...           140  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...            85  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...           120  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...            62  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...           137  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet length'] = df['tweet'].apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f14bde22",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet=df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2fcbef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " StopWords list:  ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'ff', '#ff', 'rt']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>preprocessed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>woman complain clean hous amp man alway take t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>boy dat cold tyga dwn bad cuffin dat hoe st place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>dawg ever fuck bitch start cri confus shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>look like tranni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>shit hear might true might faker bitch told ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "      <td>muthaf lie right tl trash mine bibl scriptur hymn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "      <td>gone broke wrong heart babi drove redneck crazi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "      <td>young buck wanna eat dat nigguh like aint fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "      <td>youu got wild bitch tellin lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "      <td>ruffl ntac eileen dahlia beauti color combin p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  \\\n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "...                                                  ...   \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...   \n",
       "24779  you've gone and broke the wrong heart baby, an...   \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...   \n",
       "24781              youu got wild bitches tellin you lies   \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...   \n",
       "\n",
       "                                     preprocessed_tweets  \n",
       "0      woman complain clean hous amp man alway take t...  \n",
       "1      boy dat cold tyga dwn bad cuffin dat hoe st place  \n",
       "2             dawg ever fuck bitch start cri confus shit  \n",
       "3                                       look like tranni  \n",
       "4         shit hear might true might faker bitch told ya  \n",
       "...                                                  ...  \n",
       "24778  muthaf lie right tl trash mine bibl scriptur hymn  \n",
       "24779    gone broke wrong heart babi drove redneck crazi  \n",
       "24780  young buck wanna eat dat nigguh like aint fuck...  \n",
       "24781                     youu got wild bitch tellin lie  \n",
       "24782  ruffl ntac eileen dahlia beauti color combin p...  \n",
       "\n",
       "[24783 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "other_exclusions = [\"ff\",\"#ff\",  \"rt\"]\n",
    "stopwords.extend(other_exclusions)\n",
    "stemmer = PorterStemmer()\n",
    "def preprocess(tweet):  \n",
    "    regex_pat = re.compile(r'\\s+')\n",
    "    tweet_space = tweet.str.replace(regex_pat, ' ')\n",
    "    regex_pat = re.compile(r'@[\\w\\-]+')\n",
    "    tweet_name = tweet_space.str.replace(regex_pat, '')\n",
    "    giant_url_regex =  re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "            '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    tweets = tweet_name.str.replace(giant_url_regex, '')\n",
    "    punc_remove = tweets.str.replace(\"[^a-zA-Z]\", \" \")\n",
    "    newtweet=punc_remove.str.replace(r'\\s+', ' ')\n",
    "    newtweet=newtweet.str.replace(r'^\\s+|\\s+?$','')\n",
    "    newtweet=newtweet.str.replace(r'\\d+(\\.\\d+)?','numbr')\n",
    "    tweet_lower = newtweet.str.lower()\n",
    "    tokenized_tweet = tweet_lower.apply(lambda x: x.split())\n",
    "    tokenized_tweet=  tokenized_tweet.apply(lambda x: [item for item in x if item not in stopwords])\n",
    "    tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) \n",
    "    for i in range(len(tokenized_tweet)):\n",
    "        tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "        tweets_p= tokenized_tweet\n",
    "    return tweets_p\n",
    "print(\" StopWords list: \",stopwords)\n",
    "preprocessed_tweets = preprocess(tweet)   \n",
    "df['preprocessed_tweets'] = preprocessed_tweets\n",
    "df[[\"tweet\",\"preprocessed_tweets\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86c45cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<24783x6441 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 189618 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_v = TfidfVectorizer(ngram_range=(1, 2),max_df=0.75, min_df=5, max_features=10000)\n",
    "tfidf = tfidf_v.fit_transform(df['preprocessed_tweets'] )\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f067e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.18      0.27       370\n",
      "           1       0.92      0.97      0.94      4818\n",
      "           2       0.84      0.85      0.85      1008\n",
      "\n",
      "    accuracy                           0.90      6196\n",
      "   macro avg       0.79      0.67      0.69      6196\n",
      "weighted avg       0.89      0.90      0.89      6196\n",
      "\n",
      "The accuracy of Logistic Regression is:  0.9004196255648805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chakri\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = tfidf\n",
    "y = df['class'].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = LogisticRegression().fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Logistic Regression is: \" , score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae05536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.17      0.26       370\n",
      "           1       0.93      0.96      0.94      4818\n",
      "           2       0.82      0.92      0.86      1008\n",
      "\n",
      "    accuracy                           0.90      6196\n",
      "   macro avg       0.77      0.68      0.69      6196\n",
      "weighted avg       0.89      0.90      0.89      6196\n",
      "\n",
      "The accuracy of Random Forest Classifier is:  0.9039703034215623\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score2=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Random Forest Classifier is: \" , score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83fab991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.45      0.19       370\n",
      "           1       0.91      0.69      0.79      4818\n",
      "           2       0.55      0.64      0.59      1008\n",
      "\n",
      "    accuracy                           0.67      6196\n",
      "   macro avg       0.53      0.59      0.52      6196\n",
      "weighted avg       0.80      0.67      0.72      6196\n",
      "\n",
      "The accuracy of Naive Bayes Classifier is:  0.6691413815364752\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train.toarray(),y_train)\n",
    "y_preds = model.predict(X_test.toarray())\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score3=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Naive Bayes Classifier is: \" , score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddbf2a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.24      0.32       370\n",
      "           1       0.93      0.95      0.94      4818\n",
      "           2       0.82      0.86      0.84      1008\n",
      "\n",
      "    accuracy                           0.90      6196\n",
      "   macro avg       0.75      0.68      0.70      6196\n",
      "weighted avg       0.88      0.90      0.89      6196\n",
      "\n",
      "The accuracy of Linear SVC is:  0.8957391865719819\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = LinearSVC(random_state=1)\n",
    "model.fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score4=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Linear SVC is: \" , score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68175199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.26      0.29       370\n",
      "           1       0.93      0.93      0.93      4818\n",
      "           2       0.82      0.86      0.84      1008\n",
      "\n",
      "    accuracy                           0.88      6196\n",
      "   macro avg       0.69      0.68      0.69      6196\n",
      "weighted avg       0.87      0.88      0.88      6196\n",
      "\n",
      "The accuracy of Decision Tree Classifier is:  0.8802453195610072\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = DecisionTreeClassifier(random_state=1)\n",
    "model.fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score5=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Decision Tree Classifier is: \" , score5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04203be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = ('Logistic', 'RandomForest', 'Naive_bayes', 'SVM','DecisionTree')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [score,score2,score3,score4,score5]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Algorithm Comparision for F1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc4bfe20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neg</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neu</th>\n",
       "      <th>Compound</th>\n",
       "      <th>url_tag</th>\n",
       "      <th>mention_tag</th>\n",
       "      <th>hash_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.237</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.763</td>\n",
       "      <td>-0.6876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.462</td>\n",
       "      <td>-0.9550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.5673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.249</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.669</td>\n",
       "      <td>-0.7762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>0.454</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.546</td>\n",
       "      <td>-0.8074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.4738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>0.573</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.7717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Neg    Pos    Neu  Compound  url_tag  mention_tag  hash_tag\n",
       "0      0.000  0.120  0.880    0.4563      0.0          1.0       0.0\n",
       "1      0.237  0.000  0.763   -0.6876      0.0          1.0       0.0\n",
       "2      0.538  0.000  0.462   -0.9550      0.0          2.0       0.0\n",
       "3      0.000  0.344  0.656    0.5673      0.0          2.0       0.0\n",
       "4      0.249  0.081  0.669   -0.7762      0.0          1.0       1.0\n",
       "...      ...    ...    ...       ...      ...          ...       ...\n",
       "24778  0.000  0.000  1.000    0.0000      0.0          3.0       3.0\n",
       "24779  0.454  0.000  0.546   -0.8074      0.0          0.0       0.0\n",
       "24780  0.000  0.219  0.781    0.4738      0.0          0.0       0.0\n",
       "24781  0.573  0.000  0.427   -0.7717      0.0          0.0       0.0\n",
       "24782  0.000  0.218  0.782    0.5994      1.0          0.0       0.0\n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analyzer = sia()\n",
    "def count_tags(tweet_c):  \n",
    "    \n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', tweet_c)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "def sentiment_analysis(tweet):   \n",
    "    sentiment = sentiment_analyzer.polarity_scores(tweet)    \n",
    "    twitter_objs = count_tags(tweet)\n",
    "    features = [sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],twitter_objs[0], twitter_objs[1],\n",
    "                twitter_objs[2]]\n",
    "    return features\n",
    "\n",
    "def sentiment_analysis_array(tweets):\n",
    "    features=[]\n",
    "    for t in tweets:\n",
    "        features.append(sentiment_analysis(t))\n",
    "    return np.array(features)\n",
    "\n",
    "final_features = sentiment_analysis_array(tweet)\n",
    "\n",
    "new_features = pd.DataFrame({'Neg':final_features[:,0],'Pos':final_features[:,1],'Neu':final_features[:,2],\n",
    "                             'Compound':final_features[:,3],'url_tag':final_features[:,4],'mention_tag':final_features[:,5],'hash_tag':final_features[:,6]})\n",
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b0f7224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 6448)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_2 = tfidf.toarray()\n",
    "modeling_features = np.concatenate([tfidf_2,final_features],axis=1)\n",
    "modeling_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de76188a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.19      0.28       370\n",
      "           1       0.92      0.96      0.94      4818\n",
      "           2       0.84      0.86      0.85      1008\n",
      "\n",
      "    accuracy                           0.90      6196\n",
      "   macro avg       0.78      0.67      0.69      6196\n",
      "weighted avg       0.89      0.90      0.89      6196\n",
      "\n",
      "The accuracy of Logistic Regression is:  0.9010652033570046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chakri\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(modeling_features)\n",
    "y = df['class'].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = LogisticRegression().fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Logistic Regression is: \" , score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae436792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.11      0.19       370\n",
      "           1       0.91      0.97      0.94      4818\n",
      "           2       0.83      0.83      0.83      1008\n",
      "\n",
      "    accuracy                           0.89      6196\n",
      "   macro avg       0.77      0.64      0.65      6196\n",
      "weighted avg       0.88      0.89      0.88      6196\n",
      "\n",
      "The accuracy of Random Forest Classifier is:  0.8931568754034861\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score2=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Random Forest Classifier is: \" , score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23c76de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.45      0.19       370\n",
      "           1       0.91      0.69      0.79      4818\n",
      "           2       0.55      0.64      0.59      1008\n",
      "\n",
      "    accuracy                           0.67      6196\n",
      "   macro avg       0.53      0.59      0.52      6196\n",
      "weighted avg       0.80      0.67      0.72      6196\n",
      "\n",
      "The accuracy of Naive Bayes Classifier is:  0.6693027759845062\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score3=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Naive Bayes Classifier is: \" , score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b4c764a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.25      0.34       370\n",
      "           1       0.93      0.95      0.94      4818\n",
      "           2       0.82      0.88      0.85      1008\n",
      "\n",
      "    accuracy                           0.90      6196\n",
      "   macro avg       0.76      0.69      0.71      6196\n",
      "weighted avg       0.89      0.90      0.89      6196\n",
      "\n",
      "The accuracy of Linear SVC is:  0.8979987088444158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chakri\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = LinearSVC(random_state=1)\n",
    "model.fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score4=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Linear SVC is: \" , score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb96f901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.24      0.26       370\n",
      "           1       0.93      0.94      0.93      4818\n",
      "           2       0.83      0.85      0.84      1008\n",
      "\n",
      "    accuracy                           0.88      6196\n",
      "   macro avg       0.68      0.67      0.68      6196\n",
      "weighted avg       0.87      0.88      0.88      6196\n",
      "\n",
      "The accuracy of Decision Tree Classifier is:  0.881213686249193\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = DecisionTreeClassifier(random_state=1)\n",
    "model.fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score5=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Decision Tree Classifier is: \" , score5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc5a6b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = ('Logistic', 'RandomForest', 'Naive_bayes', 'SVM','DecisionTree')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [score,score2,score3,score4,score5]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Algorithm Comparision for F1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d3e7bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc2vec_vector_0</th>\n",
       "      <th>doc2vec_vector_1</th>\n",
       "      <th>doc2vec_vector_2</th>\n",
       "      <th>doc2vec_vector_3</th>\n",
       "      <th>doc2vec_vector_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037618</td>\n",
       "      <td>-0.006811</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>-0.123213</td>\n",
       "      <td>0.080006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.060873</td>\n",
       "      <td>0.050323</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>0.084446</td>\n",
       "      <td>-0.103823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.013880</td>\n",
       "      <td>0.209109</td>\n",
       "      <td>-0.041905</td>\n",
       "      <td>-0.043280</td>\n",
       "      <td>0.035917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046911</td>\n",
       "      <td>0.127686</td>\n",
       "      <td>0.090979</td>\n",
       "      <td>0.057969</td>\n",
       "      <td>0.083035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.013062</td>\n",
       "      <td>0.032488</td>\n",
       "      <td>0.138343</td>\n",
       "      <td>-0.165039</td>\n",
       "      <td>-0.182509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>0.278782</td>\n",
       "      <td>0.189622</td>\n",
       "      <td>0.405845</td>\n",
       "      <td>-0.078538</td>\n",
       "      <td>-0.100875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>-0.149152</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.143740</td>\n",
       "      <td>-0.059088</td>\n",
       "      <td>-0.029947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>-0.217872</td>\n",
       "      <td>0.283467</td>\n",
       "      <td>0.143595</td>\n",
       "      <td>0.174069</td>\n",
       "      <td>-0.128655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>-0.045130</td>\n",
       "      <td>0.046020</td>\n",
       "      <td>0.106284</td>\n",
       "      <td>-0.068564</td>\n",
       "      <td>-0.045444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>0.456829</td>\n",
       "      <td>0.036733</td>\n",
       "      <td>0.658897</td>\n",
       "      <td>-0.318556</td>\n",
       "      <td>-0.247702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc2vec_vector_0  doc2vec_vector_1  doc2vec_vector_2  doc2vec_vector_3  \\\n",
       "0              0.037618         -0.006811          0.022569         -0.123213   \n",
       "1             -0.060873          0.050323          0.138000          0.084446   \n",
       "2             -0.013880          0.209109         -0.041905         -0.043280   \n",
       "3              0.046911          0.127686          0.090979          0.057969   \n",
       "4             -0.013062          0.032488          0.138343         -0.165039   \n",
       "...                 ...               ...               ...               ...   \n",
       "24778          0.278782          0.189622          0.405845         -0.078538   \n",
       "24779         -0.149152          0.093575          0.143740         -0.059088   \n",
       "24780         -0.217872          0.283467          0.143595          0.174069   \n",
       "24781         -0.045130          0.046020          0.106284         -0.068564   \n",
       "24782          0.456829          0.036733          0.658897         -0.318556   \n",
       "\n",
       "       doc2vec_vector_4  \n",
       "0              0.080006  \n",
       "1             -0.103823  \n",
       "2              0.035917  \n",
       "3              0.083035  \n",
       "4             -0.182509  \n",
       "...                 ...  \n",
       "24778         -0.100875  \n",
       "24779         -0.029947  \n",
       "24780         -0.128655  \n",
       "24781         -0.045444  \n",
       "24782         -0.247702  \n",
       "\n",
       "[24783 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(df[\"preprocessed_tweets\"].apply(lambda x: x.split(\" \")))]\n",
    "model = Doc2Vec(documents ,vector_size=5, window=2, min_count=1, workers=4)\n",
    "doc2vec_df = df[\"preprocessed_tweets\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\n",
    "doc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\n",
    "doc2vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9463435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 6453)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_features = np.concatenate([tfidf_2,final_features,doc2vec_df],axis=1)\n",
    "modeling_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efea161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.20      0.30       370\n",
      "           1       0.92      0.96      0.94      4818\n",
      "           2       0.83      0.86      0.85      1008\n",
      "\n",
      "    accuracy                           0.90      6196\n",
      "   macro avg       0.78      0.67      0.69      6196\n",
      "weighted avg       0.89      0.90      0.89      6196\n",
      "\n",
      "The accuracy of Logistic Regression is:  0.8999354422207876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chakri\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(modeling_features)\n",
    "y = df['class'].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = LogisticRegression().fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Logistic Regression is: \" , score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "149ab333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.09      0.15       370\n",
      "           1       0.90      0.97      0.93      4818\n",
      "           2       0.83      0.79      0.81      1008\n",
      "\n",
      "    accuracy                           0.89      6196\n",
      "   macro avg       0.79      0.62      0.63      6196\n",
      "weighted avg       0.87      0.89      0.87      6196\n",
      "\n",
      "The accuracy of Random Forest Classifier is:  0.8879922530664945\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score2=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Random Forest Classifier is: \" , score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6609708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.45      0.19       370\n",
      "           1       0.91      0.69      0.79      4818\n",
      "           2       0.55      0.64      0.59      1008\n",
      "\n",
      "    accuracy                           0.67      6196\n",
      "   macro avg       0.53      0.59      0.52      6196\n",
      "weighted avg       0.80      0.67      0.72      6196\n",
      "\n",
      "The accuracy of Naive Bayes Classifier is:  0.6693027759845062\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score3=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Naive Bayes Classifier is: \" , score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "273c799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.25      0.34       370\n",
      "           1       0.93      0.95      0.94      4818\n",
      "           2       0.82      0.87      0.85      1008\n",
      "\n",
      "    accuracy                           0.90      6196\n",
      "   macro avg       0.76      0.69      0.71      6196\n",
      "weighted avg       0.89      0.90      0.89      6196\n",
      "\n",
      "The accuracy of Linear SVC is:  0.8978373143963848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chakri\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = LinearSVC(random_state=1)\n",
    "model.fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score4=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Linear SVC is: \" , score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04bc95de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.30       370\n",
      "           1       0.93      0.92      0.93      4818\n",
      "           2       0.80      0.85      0.83      1008\n",
      "\n",
      "    accuracy                           0.87      6196\n",
      "   macro avg       0.68      0.69      0.68      6196\n",
      "weighted avg       0.87      0.87      0.87      6196\n",
      "\n",
      "The accuracy of Decision Tree Classifier is:  0.8745965138799225\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = DecisionTreeClassifier(random_state=1)\n",
    "model.fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "score5=accuracy_score(y_test,y_preds)\n",
    "print(\"The accuracy of Decision Tree Classifier is: \" , score5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfe8e368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = ('Logistic', 'RandomForest', 'Naive_bayes', 'SVM','DecisionTree')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [score,score2,score3,score4,score5]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Algorithm Comparision for F1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c62ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
