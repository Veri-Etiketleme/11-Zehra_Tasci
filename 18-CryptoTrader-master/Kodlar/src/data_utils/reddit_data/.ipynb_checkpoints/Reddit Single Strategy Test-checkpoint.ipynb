{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from num2words import num2words\n",
    "import os\n",
    "\n",
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_reader(filename):\n",
    "    con = sqlite3.connect(filename)\n",
    "    df = pd.read_sql_query(\"SELECT * FROM submissions\", con)\n",
    "    \n",
    "    \n",
    "    df = df[['created', 'author', 'title', 'url', 'score', 'num_comments', 'flair_text', 'selftext']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sql_reader(\"subreddits/Ripple/Ripple.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(coinname, df, cachetime):\n",
    "    \n",
    "    fName = 'cache/{}-{}.csv'.format(coinname,cachetime)\n",
    "    \n",
    "    if (os.path.isfile(fName)):\n",
    "        new = pd.read_csv(fName)\n",
    "    else:          \n",
    "        reddit = sql_reader('subreddits/{}/{}.db'.format(coinname, coinname))\n",
    "\n",
    "        new = pd.DataFrame(columns=['Date', 'Reddit'])\n",
    "        new['Date'] = df['Date']\n",
    "\n",
    "        oldDate = new['Date'][0]\n",
    "\n",
    "        for i in range(new.shape[0]):\n",
    "            valsBetween = reddit[reddit['created'] > oldDate]\n",
    "            valsBetween = valsBetween[reddit['created']  < new['Date'][i]]\n",
    "\n",
    "            #cols = 'title ' + valsBetween['title'] + ' score ' + valsBetween['score'].apply(lambda x: num2words(x)) + ' comments ' + valsBetween['num_comments'].apply(lambda x: num2words(x))\n",
    "            cols = 'title ' + valsBetween['title'] + ' score ' + valsBetween['score'].map(str) + ' comments ' + valsBetween['num_comments'].map(str)\n",
    "            new['Reddit'][i] = (cols.str.cat(sep='\\n'))\n",
    "            oldDate = new['Date'][i]\n",
    "        \n",
    "        new.to_csv(fName)\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc = pd.read_csv('../../CryptoScraper/cache/BTC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shresthanikesh23/.local/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/shresthanikesh23/.local/lib/python3.5/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "coins = ['Ripple']\n",
    "\n",
    "for coin in coins:\n",
    "    new = merge_data(coin, btc, cachetime='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for bitcoin twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet, time, likes, replies, retweet. Combined twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content():\n",
    "    \n",
    "    start_date = date(2013, 1, 1)\n",
    "    end_date = date(2017, 12, 31)\n",
    "    \n",
    "    combinedDf = pd.DataFrame(columns=['Tweet', 'Time', 'Likes', 'Replies', 'Retweet'])\n",
    "    \n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        d = str(single_date.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv('twitter_data\\\\bitcoin\\\\{}.csv'.format(d)).drop('Unnamed: 0', axis=1)\n",
    "            combinedDf = pd.concat([combinedDf, df[['Tweet', 'Time', 'Likes', 'Replies', 'Retweet']]]).reset_index(drop=True)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    combinedDf.to_csv('twitter_data\\\\bitcoin\\\\combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter_data\\\\bitcoin\\\\combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time'] = df['Time'].replace(to_replace=0, method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_time(x):\n",
    "    try:\n",
    "        y = time.mktime(datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").timetuple())\n",
    "                        \n",
    "    except:\n",
    "        y = 0\n",
    "                        \n",
    "    return int(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time'] = df.fillna(method='ffill')['Time'].apply(return_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time'] = df['Time'].replace(to_replace=0, method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time'] = df['Time'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('twitter_data\\\\bitcoin\\\\time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from gensim.models.doc2vec import TaggedDocument \n",
    "from gensim import utils\n",
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(data):\n",
    "    pattern = [ 'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+',  # URLs'\n",
    "                '([^a-zA-Z0-9 ]+?)', #anything else except text\n",
    "                ]\n",
    "\n",
    "    sub_pattern = re.compile('|'.join(pattern))\n",
    "    common_w = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    if isinstance(data, pd.Series):\n",
    "        \n",
    "        data = data.str.lower()\n",
    "        \n",
    "        for idx, row in enumerate(data):\n",
    "            splitRow = row.split(' ')\n",
    "            splitRow = [w for w in splitRow if not w in common_w] \n",
    "\n",
    "            data.iloc[idx] = \" \".join(splitRow)\n",
    "            \n",
    "        replaced = data.str.replace(sub_pattern, '').str.strip()\n",
    "    else:\n",
    "\n",
    "        data = data.lower()\n",
    "        splitted = data.split(' ')\n",
    "\n",
    "        newSplit = [w for w in splitted if not w in common_w] \n",
    "        word = \" \".join(newSplit)\n",
    "        replaced = re.sub(sub_pattern, '', word).strip()\n",
    "        \n",
    "    return replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_twitter_data(df):\n",
    "    \n",
    "    twitter = pd.read_csv('twitter_data\\\\bitcoin\\\\time.csv')\n",
    "    \n",
    "    new = pd.DataFrame(columns=['Date', 'Twitter'])\n",
    "    new['Date'] = df['Date']\n",
    "\n",
    "    oldDate = new['Date'][0]\n",
    "    \n",
    "    for i in range(new.shape[0]):\n",
    "        valsBetween = twitter[twitter['Time'] > oldDate]\n",
    "        valsBetween = valsBetween[twitter['Time']  < new['Date'][i]]\n",
    "\n",
    "        #cols = 'title ' + valsBetween['title'] + ' score ' + valsBetween['score'].apply(lambda x: num2words(x)) + ' comments ' + valsBetween['num_comments'].apply(lambda x: num2words(x))\n",
    "        cols = 'tweet ' + cleanData(valsBetween['Tweet']) + ' likes ' + valsBetween['Likes'].map(str) + ' replies ' + valsBetween['Replies'].map(str) + ' retweets ' + valsBetween['Retweet'].map(str)\n",
    "        new['Twitter'][i] = (cols.str.cat(sep='\\n'))\n",
    "        oldDate = new['Date'][i]\n",
    "\n",
    "    new.to_csv('twitter_data\\\\bitcoin\\\\readable.csv')\n",
    "\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('reddit_data\\\\Bitcoin-24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_twitter_data(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensim_sentence(data):\n",
    "    labeledRow=[]\n",
    "\n",
    "    for idx, row in data.iteritems():\n",
    "        labeledRow.append(TaggedDocument(utils.to_unicode(row).split(), ['Text' + '_%s' % str(idx)]))\n",
    "\n",
    "    return labeledRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterData = pd.read_csv('twitter_data\\\\bitcoin\\\\readable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterData.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc2vec(inp):\n",
    "    labeledSentences = gensim_sentence(inp)\n",
    "    \n",
    "    fname='doc2vectwitter.d2v'\n",
    "    \n",
    "    if os.path.isfile(fname):\n",
    "        docModel = Doc2Vec.load(fname)\n",
    "    else:\n",
    "        docModel = Doc2Vec(min_count=0, window=5, vector_size=300, sample=1e-4, negative=5, workers=4, epochs=5, seed=1)\n",
    "        docModel.build_vocab(labeledSentences)\n",
    "        docModel.train(labeledSentences, total_examples=docModel.corpus_count, epochs=docModel.iter)\n",
    "        docModel.save(fname)\n",
    "    \n",
    "    return docModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterData['Twitter'] = twitterData['Twitter'].fillna(value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twiterdoc = get_doc2vec(twitterData['Twitter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(docModel, out):\n",
    "    X = np.zeros((out.shape[0], 300))\n",
    "    \n",
    "    for i in range(out.shape[0]):\n",
    "        X[i] = docModel.docvecs['Text_'+str(i)]\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterFeatures = pd.DataFrame(process_data(twiterdoc, twitterData['Twitter']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterFeatures['Date'] = twitterData['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterFeatures = twitterFeatures.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterFeatures.to_csv('twitter_data\\\\bitcoin\\\\twitterFeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc2vec_reddit(inp, coinname):\n",
    "    labeledSentences = gensim_sentence(inp)\n",
    "    \n",
    "    fname='doc2vecreddit-{}.d2v'.format(coinname)\n",
    "    \n",
    "    if os.path.isfile(fname):\n",
    "        docModel = Doc2Vec.load(fname)\n",
    "    else:\n",
    "        docModel = Doc2Vec(min_count=0, window=5, vector_size=300, sample=1e-4, negative=5, workers=4, epochs=5, seed=1)\n",
    "        docModel.build_vocab(labeledSentences)\n",
    "        docModel.train(labeledSentences, total_examples=docModel.corpus_count, epochs=docModel.iter)\n",
    "        docModel.save(fname)\n",
    "    \n",
    "    return docModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = ['Bitcoin', 'ethereum', 'Monero', 'dashpay', 'dogecoin', 'litecoin', 'Ripple', 'Stellar']\n",
    "\n",
    "bigDf = pd.DataFrame(columns=['Date', 'Reddit'])\n",
    "\n",
    "doc2vecs = {}\n",
    "\n",
    "for coin in coins:\n",
    "    df = pd.read_csv('reddit_data//{}-24.csv'.format(coin))\n",
    "    doc2vecs[coin] = get_doc2vec_reddit(df['Reddit'].fillna(value=''), coin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redditFeatures = {}\n",
    "\n",
    "for coin in coins:\n",
    "    redditFeatures[coin] = pd.DataFrame(process_data(doc2vecs[coin], pd.read_csv('reddit_data//{}-24.csv'.format(coin))['Reddit']))\n",
    "    redditFeatures[coin]['Date'] = twitterData['Date']\n",
    "    redditFeatures[coin] = redditFeatures[coin].set_index('Date')\n",
    "\n",
    "    redditFeatures[coin].to_csv('reddit_data\\\\\\\\{}Features.csv'.format(coin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
